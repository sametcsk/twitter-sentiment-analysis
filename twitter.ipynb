{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aead6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9073dbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['sentiment', 'id', 'date', 'query', 'user', 'text']\n",
    "df = pd.read_csv('training.1600000.processed.noemoticon.csv', \n",
    "                 encoding='latin-1', \n",
    "                 names=columns)\n",
    "\n",
    "print(\"Dataset Boyutu:\", df.shape)\n",
    "print(\"\\nİlk 5 satır:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nSentiment Dağılımı:\")\n",
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f0bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample=pd.concat([\n",
    "    df[df[\"sentiment\"]==0].sample(200000,random_state=42),\n",
    "    df[df[\"sentiment\"]==4].sample(200000,random_state=42)\n",
    "]).sample(frac=1,random_state=42).reset_index(drop=True)\n",
    "\n",
    "df_sample[\"sentiment\"]=df_sample[\"sentiment\"].map({0:0,4:1})\n",
    "df_sample=df_sample[[\"text\",\"sentiment\"]]\n",
    "\n",
    "print(\"Sample Dataset:\")\n",
    "print(df_sample.head(10))\n",
    "print(\"\\nYeni Sentiment Dağılımı:\")\n",
    "print(df_sample['sentiment'].value_counts())\n",
    "print(\"\\nÖrnek Pozitif Tweetler:\")\n",
    "print(df_sample[df_sample['sentiment'] == 1]['text'].head(3).values)\n",
    "print(\"\\nÖrnek Negatif Tweetler:\")\n",
    "print(df_sample[df_sample['sentiment'] == 0]['text'].head(3).values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc0e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # 1. Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Mention'ları temizle (@username)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    # 3. URL'leri temizle\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # 4. Noktalama işaretlerini temizle (sadece harf ve boşluk kalsın)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # 5. Fazla boşlukları temizle\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    #6. Stopwords ve kısa kelimeleri temizle\n",
    "    tokens=text.split()\n",
    "    tokens=[word for word in tokens if word not in stop_words and len(word)>2]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "print(\"ÖNCE vs SONRA Karşılaştırması:\\n\")\n",
    "for i in range(5):\n",
    "    original = df_sample.iloc[i]['text']\n",
    "    cleaned = clean_text(original)\n",
    "    sentiment = \"POZİTİF\" if df_sample.iloc[i]['sentiment'] == 1 else \"NEGATİF\"\n",
    "    \n",
    "    print(f\"{sentiment}\")\n",
    "    print(f\"ÖNCE:  {original}\")\n",
    "    print(f\"SONRA: {cleaned}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aaac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Veri Temizlemesi\")\n",
    "\n",
    "start_time = time.time()\n",
    "df_sample[\"cleaned_text\"] = df_sample[\"text\"].apply(clean_text)\n",
    "end_time = time.time()\n",
    "print(f\"Veri temizleme süresi: {end_time - start_time:.2f} saniye\")\n",
    "\n",
    "print(f\"\\n Boş tweet sayısı: {(df_sample['cleaned_text'] == '').sum()}\")\n",
    "df_sample = df_sample[df_sample['cleaned_text'] != ''].reset_index(drop=True)\n",
    "print(f\"\\n Kalan tweet sayısı: {len(df_sample)}\")\n",
    "\n",
    "print(\"\\n Temizlenmiş Veri Örneği:\")\n",
    "print(df_sample[['cleaned_text', 'sentiment']].head(10))\n",
    "\n",
    "df_sample['word_count'] = df_sample['cleaned_text'].apply(lambda x: len(x.split()))\n",
    "print(\"\\n Kelime Sayısı İstatistikleri:\")\n",
    "print(df_sample['word_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52906646",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_text=\" \".join(df_sample[df_sample['sentiment']==1]['cleaned_text'])\n",
    "negative_text=\" \".join(df_sample[df_sample[\"sentiment\"]==0][\"cleaned_text\"])\n",
    "\n",
    "def plot_wordcloud(text,title):\n",
    "    wordcloud=WordCloud(width=800,height=400,random_state=21,max_words=100,background_color='white').generate(text)\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "print(\"Pozitif Tweetlerde En Sık Geçen Kelimeler:\")\n",
    "plot_wordcloud(positive_text, \"Pozitif Kelime Bulutu\")\n",
    "\n",
    "print(\"Negatif Tweetlerde En Sık Geçen Kelimeler:\")\n",
    "plot_wordcloud(negative_text, \"Negatif Kelime Bulutu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7471a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_sample[\"cleaned_text\"]\n",
    "y=df_sample[\"sentiment\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      \n",
    "    random_state=42,    \n",
    "    stratify=y          \n",
    ")\n",
    "print(\"Veri Bölünümü\")\n",
    "print(f\"Training set: {len(X_train)} tweet\")\n",
    "print(f\"Test set: {len(X_test)} tweet\")\n",
    "print(f\"\\n Training set sentiment dağılımı:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\n Test set sentiment dağılımı:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1251bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features=15000,      \n",
    "    ngram_range=(1, 3),     \n",
    "    min_df=2,                \n",
    "    max_df=0.95,             \n",
    "    sublinear_tf=True,       \n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    use_idf=True,\n",
    "    smooth_idf=True\n",
    ")\n",
    "\n",
    "X_train_tfidf=tfidf.fit_transform(X_train)\n",
    "X_test_tfidf=tfidf.transform(X_test)\n",
    "\n",
    "print(f\"Training: {X_train_tfidf.shape}\")\n",
    "print(f\"Test: {X_test_tfidf.shape}\")\n",
    "print(f\"\\n Toplam kelime sayısı: {len(tfidf.get_feature_names_out())}\")\n",
    "\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "print(f\"\\n İlk 20 kelime:\")\n",
    "print(feature_names[:20])\n",
    "print(f\"\\n Son 20 kelime:\")\n",
    "print(feature_names[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fa652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(\n",
    "    C=2.0,                   \n",
    "    max_iter=1000,\n",
    "    solver='liblinear',      \n",
    "    random_state=42\n",
    ")\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "lr_pred = lr_model.predict(X_test_tfidf)\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "print(f\"Logistic Regression Accuracy: {lr_accuracy:.4f} ({lr_accuracy*100:.2f}%)\\n\")\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "nb_pred = nb_model.predict(X_test_tfidf)\n",
    "nb_accuracy = accuracy_score(y_test, nb_pred)\n",
    "print(f\"Naive Bayes Accuracy: {nb_accuracy:.4f} ({nb_accuracy*100:.2f}%)\\n\")\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "rf_pred = rf_model.predict(X_test_tfidf)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f} ({rf_accuracy*100:.2f}%)\\n\")\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\" Modellerin Karşılaştırılması:\")\n",
    "print(\"=\" * 60)\n",
    "results = [\n",
    "    (\"Logistic Regression\", lr_accuracy),\n",
    "    (\"Naive Bayes\", nb_accuracy),\n",
    "    (\"Random Forest\", rf_accuracy)\n",
    "]\n",
    "\n",
    "for model_name, acc in sorted(results, key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{model_name:.<30} {acc*100:.2f}%\")\n",
    "\n",
    "print(\"\\n En İyi Modelimiz:\", max(results, key=lambda x: x[1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbd5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, best_pred, \n",
    "                          target_names=['Negatif', 'Pozitif']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b87f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=lr_model\n",
    "best_pred=lr_pred\n",
    "best_acc=lr_accuracy\n",
    "\n",
    "cm = confusion_matrix(y_test, best_pred)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Negatif','Pozitif'],\n",
    "            yticklabels=['Negatif','Pozitif'],\n",
    "            cbar_kws={'label':'Tweet Sayısı'},\n",
    "            annot_kws={'size':16})\n",
    "plt.title(f\"Confusion Matrix - Logistic Regression\\nAccuracy: {best_acc*100:.2f}%\", \n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.ylabel(\"Gerçek Sentiment\")\n",
    "plt.xlabel(\"Tahmin Edilen Sentiment\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8e412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Logistic Regression\", \"Naive Bayes\", \"Random Forest\"]\n",
    "accuracies = [lr_accuracy*100, nb_accuracy*100, rf_accuracy*100]\n",
    "colors = [\"blue\", \"green\", \"red\"]\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "bars = plt.bar(models, accuracies, color=colors, edgecolor=\"black\", linewidth=1.5)\n",
    "\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 1, \n",
    "             f'{acc:.2f}%', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.axhline(y=50, color='red', linestyle='--', linewidth=2, alpha=0.5, \n",
    "            label='Rastgele Tahmin (50%)')\n",
    "plt.ylim(0, 100)\n",
    "plt.ylabel('Accuracy (%)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Modeller', fontsize=14, fontweight='bold')\n",
    "plt.title('Model Performans Karşılaştırması', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74c7fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tahmin_et(text):\n",
    "    cleaned = clean_text(text)\n",
    "    \n",
    "    vectorized = tfidf.transform([cleaned])\n",
    "    \n",
    "    prediction = best_model.predict(vectorized)[0]\n",
    "    proba = best_model.predict_proba(vectorized)[0] \n",
    "    \n",
    "    sentiment = \"POZİTİF \" if prediction == 1 else \"NEGATİF \"\n",
    "    confidence = proba[prediction]\n",
    "    print(f\"Confidence: {confidence*100:.2f}%\")\n",
    "    \n",
    "    print(f\"Tweet: '{text}'\")\n",
    "\n",
    "    print(f\"Modelin Gördüğü: '{cleaned}'\") \n",
    "    print(f\"Tahmin: {sentiment}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# Pozitif\n",
    "tahmin_et(\"I love this product, it is amazing and perfect!\")\n",
    "\n",
    "#Negatif\n",
    "tahmin_et(\"This is the worst movie I have ever seen. Terrible acting.\")\n",
    "\n",
    "#Karışık\n",
    "tahmin_et(\"I am so happy that I bought this.\")\n",
    "tahmin_et(\"My flight was delayed and my luggage is lost.\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    kullanici_girisi = input(\"\\nBir İngilizce cümle yazın: \")\n",
    "    \n",
    "    if kullanici_girisi.lower() == 'q':\n",
    "        print(\"Programdan çıkılıyor... \")\n",
    "        break\n",
    "\n",
    "    tahmin_et(kullanici_girisi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689ccbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c95a0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
